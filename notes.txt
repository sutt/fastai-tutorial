9.26

	audit calcs
		- the mse/r2 relationship might not be perfect because diff splits, 
			(at least between sklearn and pytorch models)
			[ ] check the baseline err for each
		
	[x] is r2 symmetric? -> no
	
	[x] correct order of pred, actual on r2_score
		[x] twice in mnist_metrics
		[x] anywhere else?
	
	[x] add target to mnist_metrics
	
	[x] rerun metrics 1 and 3
	[x] concat all tables
			
	[x] why is dist_r2 negative for topleft resnet model?
		[x] why is it positive for net3 with same dist_avg?
		-> mistake in calc of baseline
		
	[x] plot dist_r2 vs dist_avg
		-> looks like there's a difference in split
		-> it's still not looking right

	[ ] why is mse and dist_avg different b/w net3 and resnet18?
	
	[ ] commit
	
9.25

	tut
		[x] multi-index dataframe
		
		[x] metrics-1: add resnets
			[x] match to their output on training history
			[x] match mse b/w fastai
			
		[x] metrics-2: add base models
			[x] how to handle 2 y scalars in evaluation?
			[x] how to handle unflow field for the calcs? to match mse
			[x] build sk helper function
			
		
		[x] more metrics
			[x] why is r2 weird on metrics3, center ?
			
				note: changing y_range on inference also changes predictive accuracy of predictions (more liberal -> worse acc)
				
				[x] retrain the model and load into metrics-3
					
					re-running with model_fn = ____4.pth
					
					>gcloud compute scp jupyter@may2-instance-1:~/fastai-tutorial/ model/pt3_center_4.pth
					
					[x] what is the cloud conda env to use?
						-> using fastai2-aug-kernel
					
					[x] why does function eda_fig_1 -> RegressionBlock, break?
						-> just a refactor from fastai2
			
			
		remaining mysteries on resnet metrics:
		
			- might one to save these mysteries until we port to new fastai version
			
			[ ] why did my re-run of topleft training loop result in 45 instead 58 r2? esp. when I am using set_seed()?
			
			[ ] why does metrics_df calc differently on cloud and locally with "same model" and dataset? 
				Split? -> no those are matching
				
			[ ] r2 looks fishy in other areas too, why not corresponding with mse?
				- could it be a problem with r2_score()?
				
		[ ] misc
			[ ] re-populate tut_multitask_3 missing cell
			[ ] commit new metrics + tbls
		
		[ ] metrics todos
			[ ] build baseline
			[ ] with baseline we can plot r2 vs mse and see if identity exists?
					
	
		[ ] metrics-4 
			[ ] BaseNet
			[ ] FeatsNet

		
		other ideas:
			[ ] maybe decreasing the batchsize during training featsnet?
			[ ] why is there a good fit for x on topleft and y on topleft?
				- can display pred vs actual with:
					- title showing r2
					- error bars around y = x
			[ ] audit the centerpoint calc, it looks fishy for one of the 7's
			
		[ ] Bring features from featsnet into classic-ml fitting
			[ ] is there a point that's exactly correct?
		
		[ ] change the names of notebook
			10_glossary_subject_v1.ipynb
			20_research_subject_v2.ipynb
	
	
	obj-detect
		[ ] where does the trained model + arch live on filesystem?
		[ ] some kind of bbox utility?
			- can take from fastai or from icevision
	
	
	notes:
		"keypoint" detection - Review of Lit:
				
				COSFIRE filters, Azzopardi 2013				https://www.um.edu.mt/library/oar/bitstream/123456789/8375/1/PAMI2013.pdf
				https://arxiv.org/pdf/1904.00889.pdf
				
				Eklund 2020 - Segmentation of floor plans + keypoints for the corners
				https://www.diva-portal.org/smash/get/diva2:1450823/FULLTEXT01.pdf
				
				R-Cnn 2015	https://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf
				
				Primer on keypoints	https://www.sicara.ai/blog/2019-07-16-image-registration-deep-learning
					keypoints from SURF/SIFT are used fro stiching/registration
					
					Looking at the invariant features of CNN's
					e.g. https://arxiv.org/ftp/arxiv/papers/1904/1904.00197.pdf
							
		docs have a model for this... does it work?
		https://pytorch.org/docs/stable/torchvision/models.html#keypoint-r-cnn
		
		Detectron Repo, a c/np based framework agnositc (?) 	
		https://github.com/zhaoweicai/Detectron-Cascade-RCNN/blob/master/MODEL_ZOO.md
		
			https://arxiv.org/abs/1906.09756
			
		Optical Flow papers and benchmarks
		https://benchmarks.ai/kitti-optical-flow-2015
		
		
		keep fn key locked on	https://www.reddit.com/r/Surface/comments/7wvy3t/can_the_surface_book_2_lock_the_fn_key/
	
		
		

9.24

	[x] do a commit
	
	[ ] how to catch the histroy of a training run?
	
		fastai issue: CSVLogger append=True doesn't work great
		
	[ ] build class to capture training history
	[ ] build a major results notebook
		- save tabular results as jsons, then add a property about where it came from
		
	[ ] port the notebooks to new version of fastai
	
	[ ] It would be interesting to track training loss without dropout
	
	[ ] How does ridge do on topleft task?
	[ ] How do differnet models do with the expanded feature set?
	
		
	
	Notes on ML:
	
		pretrained model zoo
		https://github.com/balavenkatesh3322/CV-pretrained-model
		
		tips + links from competitions
		https://neptune.ai/blog/binary-classification-tips-and-tricks-from-kaggle
		
		https://www.reddit.com/r/computervision/
	
		ping pong self balancing delta robot	https://www.reddit.com/r/computervision/comments/htoumy/ping_pong_ball_stabilization/
		
			Showcase video
			https://www.youtube.com/watch?v=57DbEEBF7sE
			
			Secret Instructables
			https://www.instructables.com/id/XBall-Balancing-PID-System/
			
			The insturctables archived
			http://archive.is/pXzCq
			
			404 Instructables
			https://www.instructables.com/id/Ball-Balancing-PID-System/
			
			Johan Link, 19 year old etudiant in Switzerland
				https://www.youtube.com/channel/UCKqAb79t9iPfma8BsR_C8jA
				https://www.instructables.com/member/Johan+Link/
				https://www.linkedin.com/in/johan-link-aa538318a/
				
			Another Delta bot - based on capcitance positioning	https://www.instructables.com/id/PID-Controlled-Ball-Balancing-Stewart-Platform/
	
		CV team on producthunt
		https://www.producthunt.com/posts/picsell-ia-3
		
		Variational Auto Encoders - for generative nets
			https://jaan.io/what-is-variational-autoencoder-vae-tutorial/	https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf
		
	
9.23

	[x] Redo notebook custom-...-3 with topleft as the target
	[x] Build an import script for setup
	
	[ ] tut_multitask_3 - bottom section is wrong, doesn't account for topleft task
		[ ] Net3 is exceeds resnet on centerpoint but does it on topleft?
		[ ] Part _04.ipynb also does center point instead of topleft
	
	[x] Do a commit
	
	[x] Display the argmax features with multiplots
	
	[ ] Add an optional other dim to BaseNet, it seems to help so much with topleft
	
	[x] bring pts features into FeatsNet
	
	Interesting idea: the threshold of the cutoff could be differentiable
		Could this be done with a RELU? or doing an .add_ with a torch.where
		But this requires the argmax and "matmul-ish" steps also be differential, right?
		
		[ ] do .build_feats and concat after the first layer to see if you can do differences?
	
	[ ] need a relu layer in my BaseNet?
	

9.21

	NN Tutorial
		Priorities
		[ ] Redo notebook custom-...-3 with topleft as the target
		
		
		Thoughts
		[ ] One thing I'd like to see is adding dummy variables
			- either constants or random values
		[ ] Can I add argmax / argmin in later layers too?
		[ ] What exactly do the argmax features do?
			- why aren't the new features exact matches to the synthetic point targets?
				- could they be made so?
		[ ] Could this model be even better with more hidden layers?
	
	SQL Review
	[ ] connect in jupyter to mysql
	[ ] Convert the problem to mysql
	

9.20

Abandon gumbel softmax for now, work on trying to get argmax into the initial layer

	[x] new notebook
	[x] replicate exisiting work
	[x] look at iafoss's solution, how is his differentiable?
		-> it only changes dimensions of the tiles and puts it thorugh two separate networks
	[x] do we need the pprocessing layers in the init?
		-> to update the weights/biases-parameters, yes
		-> to do a forward pass, no
	
	

9.19

How to concat layers?
https://discuss.pytorch.org/t/concatenate-layer-output-with-additional-input-data/20462/2

What does Unpool do?

9.18

Interesting to see how quickly you can converge in a bare bones mm-style NN task of predicting y from an arbitrary task. (from pytroch demo)

Maybe what we want is a custom nn.Module that does argmin / argmax as additional features when coming into the head.

	see:	https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html#sphx-glr-beginner-examples-nn-two-layer-net-module-py

	
	Interesting challenge case: where the 3's look at topleft point and the 7's look at the middle point.
	
	Or extend this further, to all digits in mnist

	
 Combining digit classification and dependant point location as a task would have contributions to the OCR modelling space and even more broadly to the idea of understanding documents and diagrams.
 
	What are examples of OCR datasets?
	
	What are examples of OCR arch's?
	

Two strong claims I am making is that:
1. This task can't be done well with existing backbone + head. 
2. But I am saying some new form of either a head or full-bacbone-and-head does solve this problem well.

In regards to #1, what ways could I be wrong?

	One possibility is that image size is the problem and dimension redcution whem doing convolutional pooling is erasing the information.
	
	Maybe Min/Max Pooling would help my backbone preserve the information?
	
	Another option is is that I need to do lots of finetuning or feezing or re-training the backbone, or something?
	
	Could be some kind of batch/learning rate thing?
	
Embedding Argmax with autograd enabled:

	https://discuss.pytorch.org/t/differentiable-argmax/33020/8
	
	Could I do a set of AvgMinPool with succesive reduction
	https://discuss.pytorch.org/t/predict-a-categorical-variable-and-then-embed-it-one-hot/85555/5
	
	why is argmin differentiable? 	https://stackoverflow.com/questions/54969646/how-does-pytorch-backprop-through-argmax
	
	"Siamese Network"
	
	"embeddings" in the network
	
	
We can check for if resnet has a "bad backbone" (loses information) or just needs a "better head" (in that the backbone is essentially worthless).

	We can flatten the img data initially and then compare that against the feature-map created by backbone...both fed into the same head...that will give us a relevant comparison.
	
What arch uses two pooling layers?
	-> Resnet18 does at the beginning of head: Avg + Max Pooling
	
	
	
Todo:
[x] replicate existing work
[x] add a torch.nn.Module to replicate the layers thing
[ ] do a forward pass on resnet18,
	[ ] examine traditional pooling
[ ] Replicate the argmax() with nn functions
[ ] 
	


9.8

"TopLeft" target is kind of an "arbitrary" point but should be close to what a bounding box is trying to predict. Why so poor?
    - note: that the point (min(cols), min(rows)) is the true topleft corner of the bounding box

Jeremy chops it up
https://www.wandb.com/podcast/jeremy-howard

My heads so far, like - Net3, Relu4, etc - all used flatten as the first step. That's a problem right there.
    maybe I can add on 

[ ] Get a RCNN pytorch model and watch how the head works?

User submitted SSD in a notebook with fastai_v1
https://forums.fast.ai/t/dynamic-ssd-implementation-for-fastai-v1/36161/3
https://github.com/rohitgeo/singleshotdetector
    -> in my folder as ssd_fastai1.ipynb

Official fastai obj-detector (RetinaNet) discussion:
https://forums.fast.ai/t/object-detection-in-fast-ai-v1/29266

    notebook
    https://github.com/fastai/fastai_dev/blob/master/dev_nb/102a_coco.ipynb

Answers to "NN object localization"

    My project doesn't work
    https://stats.stackexchange.com/questions/362480/object-localization-with-cnn

    Tutorial from pytorch, extensive
    https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html
    
    Tutorial from pytorch, smaller
    https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/

    Quick review of main algos
    https://medium.com/machine-learning-bites/deeplearning-series-objection-detection-and-localization-yolo-algorithm-r-cnn-71d4dfd07d5f

    Review of Lit
    https://machinelearningmastery.com/object-recognition-with-deep-learning/

    Review of the Lit
    https://leonardoaraujosantos.gitbook.io/artificial-inteligence/machine_learning/deep_learning/object_localization_and_detection

    Giant blog review of lit
    https://dudeperf3ct.github.io/object/detection/2019/01/07/Mystery-of-Object-Detection/

    Deep step by step guide to object detection
    https://towardsdatascience.com/building-your-own-object-detector-pytorch-vs-tensorflow-and-how-to-even-get-started-1d314691d4ae

    Review of field + some code
    https://medium.com/analytics-vidhya/guide-to-object-detection-using-pytorch-3925e29737b9

    Papers with code Archive
    https://paperswithcode.com/task/object-localization

9.6

[ ] Investigate new version for bug, propose fix
    CSVLogger values get erased after calling get_preds()

