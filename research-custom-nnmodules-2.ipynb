{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research: how to do *differential* argmax/argmin\n",
    "\n",
    "Consolidating findings from previous book in this series here.\n",
    "\n",
    "**Progress 9.20.2020:** Gumbel Softmax is looking less promising and \n",
    "\n",
    "**Notes:**\n",
    "https://discuss.pytorch.org/t/differentiable-argmax/33020/106\n",
    "\n",
    "**Talk Thru:** To get a NN to estimate the \"top-left-point\" function, we'll want to add argmax/argmin style functions onto the network which will allows us to predict the \"top-most\" / \"left-most\" point, etc. \n",
    "\n",
    "In this first stage, in *research-custom-nnmodules-1.ipynb*, we looked at building our own custom model pytorch style. This allows us to use more than simply the nn.builtins in Sequential, and possibily add our own custom layer function.\n",
    "\n",
    "One issue to account for is that each layer within the netork must be differentiable with a forward and backward method that autograd can use.\n",
    "\n",
    "To accomplish that, we looked at several methods of doing this:\n",
    " \n",
    " - Using `nn.MaxPool1d(return_indices=True)` which will simulate argmax when using the returned indices. Since MaxPool1d only work over 1-dimension, we transposed the image, pooled again, concatenating the result for each row, with result for each col. The problem with this method is that the indices go not have a `grad` (but the other tensor with the pooling process, the max-values in this case does have a `grad`).\n",
    " \n",
    " \n",
    " - Below, we explore using `gumbel_softmax` perhaps with a pre-processing of rectification somewhere.\n",
    " \n",
    " \n",
    " - Another option to consider is doing a straight-up non-differential argmax and using that as an \"embedding\" layer which may work without a chain of grad's.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - imported from previous books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 28, 28])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import copy as copyroot\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from fastai2.basics import *\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from module.mnist_helpers import build_df, eda_fig_1\n",
    "from module.mnist_helpers import img_pt_plot, train_history_dualplot\n",
    "\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "df = build_df(path)\n",
    "df.head(2)\n",
    "\n",
    "y_names = [\n",
    "    'point_topleft_x', \n",
    "    'point_topleft_y',\n",
    "    'point_center_x',\n",
    "    'point_center_y'\n",
    "    ]\n",
    "\n",
    "db =   DataBlock(blocks=(ImageBlock(cls=PILImageBW), \n",
    "                         PointBlock), \n",
    "                splitter=RandomSplitter(seed=0),\n",
    "                get_x=ColReader('fn', pref=path),\n",
    "                )\n",
    "\n",
    "db_1_topleft = copyroot.deepcopy(db)\n",
    "db_1_center  = copyroot.deepcopy(db)\n",
    "db_2         = copyroot.deepcopy(db)\n",
    "\n",
    "def set_get_y(db, cr):\n",
    "    db.get_y = cr\n",
    "    db.getters[db.n_inp:] = L(db.get_y)\n",
    "\n",
    "set_get_y( db_1_topleft, ColReader(y_names[:2]) )\n",
    "set_get_y( db_1_center,  ColReader(y_names[2:]) )\n",
    "set_get_y( db_2,         ColReader(y_names) )\n",
    "\n",
    "dl_1_topleft = db_1_topleft.dataloaders(df)\n",
    "dl_1_center  = db_1_center.dataloaders(df)\n",
    "dl_2         = db_2.dataloaders(df)\n",
    "\n",
    "# remake a datablock with BW-style images\n",
    "\n",
    "y_names = [\n",
    "    'point_topleft_x', \n",
    "    'point_topleft_y',\n",
    "    'point_center_x',\n",
    "    'point_center_y'\n",
    "    ]\n",
    "\n",
    "dblock = DataBlock(blocks=(ImageBlock(cls=PILImageBW), PointBlock), \n",
    "                  splitter=RandomSplitter(),\n",
    "                   get_x=ColReader('fn', pref=path),\n",
    "                   get_y=ColReader(y_names[2:]),\n",
    "                  )\n",
    "\n",
    "dls = dblock.dataloaders(df)\n",
    "\n",
    "x, y = dls.one_batch()\n",
    "\n",
    "x.shape\n",
    "\n",
    "x_2 = x[:2]\n",
    "x_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The example we'll consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAIeElEQVR4nO3da4xU9RkG8OfZZXe5K4srEm4LlNRaY2u7kUpLsCGkK7bRpG0KaZt+oKEfQDTR1lVr0kA/kDYabW3TskLXDxQLto1itETphRgVoQmlS+kCS1zZQgTEWlIbZNl/P+wI8x7Zubwzc86Z2eeXkN33zOX8IQ9n/nMu72EIASLFqkt6AFKdFBxxUXDERcERFwVHXBQccSkpOCTbSfaQPEKyo1yDkvSjdz8OyXoAhwAsAdAPYA+A5SGEf5RveJJWo0p47U0AjoQQjgIAyacA3A5g2OA0simMxrgSVilxO4t3TocQWqLLSwnONADHsup+APNzvWA0xmE+F5ewSonbS+HpvsstLyU4vMyyD33ukVwJYCUAjMbYElYnaVLK5LgfwIysejqA49EnhRA2hBDaQghtDWgqYXWSJqUEZw+AeSRnk2wEsAzAs+UZlqSd+6MqhDBAcjWAHQDqAWwKIRwo28gk1UqZ4yCE8DyA58s0Fqki2nMsLgqOuCg44qLgiIuCIy4KjrgoOOKi4IiLgiMuJe05TjO2XW/q3q9MMPVDd2wz9fIJbxX1/l8+ctvF3995dJZ5bOzvdxf1XtVIWxxxUXDEpWY+qk6uWmDq7ff9yNQt9bnPBRoscn3bPrL94u9nf/K+eezMo/a5a/91m6l7H7/W1BN//VqRa0+etjjiouCIi4IjLjUzxxmM/E3yzWnK6Yq60aaeUGdnTBtnvWjqU+ufM/UDdy419dtfbzb1wNE3Shxh+WmLIy4KjrgoOOJSM3OciW9eMHXfgN23MmtUo6m737fXDq7pWZbz/Rvr7fu3X3PpSucG2sdWTerJ+V7R+VfnzJ2mXnzjalOP0xxHaoWCIy4KjrjUzBwneirDsin3mrr+nH1+88H/mnr8a/tzvj9H2X+qXTM/Puxzn5vzeVOv29Bp6rYmOyeKuvquo6Y+9/p0Uw8c68/5+jhoiyMuCo64KDjiUjNznKiWX7xa1vcLAwOmznX8aMxgsWf3WFvm2j4OCxevMfWkLs1xpErlDQ7JTSRPkuzOWtZM8kWShzM/J1V2mJI2hWxxugC0R5Z1ANgZQpgHYGemlhEk7xwnhLCLZGtk8e0Absn8/iSAPwO4r4zjqipvf/tmU3/pzr+YOt9+m6hfvdtq6pZdJ0xtZ1vJ8M5xpoQQTgBA5ufV5RuSVIOKf6tSu9ra5N3ivEVyKgBkfp4c7olqV1ubvFucZwF8C8D6zM9nyjaitKqrN2X93EuX/bavftk81nHV30pa1R9O2cuXq/KcY5JbALwK4KMk+0muwFBglpA8jKGbgKyv7DAlbQr5VrV8mId0U4YRTHuOxaVmj1UVK3q+Td0c27rk0A9sm5QDiy6dY1MX+f+X70jVe4PnTX38gr2fyplH7LrHoLgWLHHQFkdcFBxxUXDERXOcjL4HbzL1vpWPVWxdXzzwDVOPb7fnGI/B6xVbd7loiyMuCo646KMqo2WBPXUh+hU7lwbawxHn89yRe8L37cFe3w28k6UtjrgoOOKi4IiL5jgZTT+80tSDTxV+iUt0TjOY56DDtb/8p6lf+ak99XRSV3kv7akEbXHERcERFwVHXBhCfHsRJrI5zGc6z/9ikz0fuq/j0/YJ158d9rX7F3SZOt8cJ+rMBduDZXHn90w9Y90rRb1fOb0Unv5rCKEtulxbHHFRcMRFwREXzXHKIHo3vqgrHztu6idbd+R8/qnInGfJE3bOM3NtfHMezXGkrBQccVFwxEXHqsog7O3O+XjvE/ZY1O6H/mjq+U32cploy/7vfM22dnthrT2ulgRtccRFwREXBUdcanaOM+qaKab+3w0zKrau/lsaTH3DwsOm7pr1Y1M3x3jbx0rRFkdcCumPM4Pkn0geJHmA5F2Z5WpZO4IVssUZAHBPCOFjAD4DYBXJ66CWtSNaIY2VTgD4oMPoWZIHAUxDylvW/nthq6l/8/DDpi7n7aU/3OYkej5O9c9pooqa42T6Hd8IYDfUsnZEKzg4JMcD+C2Au0MI/ynidStJ7iW59zzO5X+BVIWCgkOyAUOh2RxC+F1mcUEta9WutjblneOQJICNAA6GEB7JeijVLWvHb7O3Wrx7zR2m3jznhTiHU5R3B+2tr3++/VZTz0by110VsgPwswC+CeDvJPdllj2AocBszbSvfRPAVyszREmjQr5VvQyAwzxce6fzSUG051hcavZYVdR7K64w9bqtnzL1PZPtnGhsnT3+VEnrT3/C1NsfX2Tq2Z3Jz2mitMURFwVHXBQccRkxc5wLh3pNveeTtm/fwo57TT3zC2+YeuPcraZetPm7l4rod84iL1Wb12n7D04+mr45TZS2OOKi4IiLLgGWnHQJsJSVgiMuCo64KDjiouCIi4IjLgqOuCg44qLgiIuCIy4KjrgoOOKi4IiLgiMuCo64xHo+DslTAPoAXAXgdGwrLk5ax5bUuGaFEFqiC2MNzsWVknsvd3JQGqR1bGkblz6qxEXBEZekgrMhofUWIq1jS9W4EpnjSPXTR5W4xBocku0ke0geIZloe1uSm0ieJNmdtSwVvZurobd0bMEhWQ/gZwBuBXAdgOWZfslJ6QLQHlmWlt7N6e8tHUKI5Q+AmwHsyKrvB3B/XOsfZkytALqz6h4AUzO/TwXQk+T4ssb1DIAlaRpfnB9V0wAcy6r7M8vSJHW9m9PaWzrO4Fyuj6C+0uXg7S0dhziD0w8g+94/0wEcH+a5SSmod3McSuktHYc4g7MHwDySs0k2AliGoV7JafJB72Ygwd7NBfSWBpLuLR3zJG8pgEMAegE8mPCEcwuGbm5yHkNbwxUAJmPo28rhzM/mhMb2OQx9jO8HsC/zZ2laxhdC0J5j8dGeY3FRcMRFwREXBUdcFBxxUXDERcERFwVHXP4PrL4WhkQb0tcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2)); plt.imshow(x_2[0].squeeze(0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine `gumbel_softmax`\n",
    "This is nice because it gives us a differential argmax-like via a built-in.\n",
    "\n",
    "Problems to solve:\n",
    " \n",
    " - when there a full rows and columns of zeros, an arbitrary index is chosen.\n",
    " \n",
    " \n",
    " - we don't want the true argmax, but the first/last element that is non-zero, meaning we want to consider activation =0 vs. >0.\n",
    " \n",
    "    - perhaps we can do argmins on rotated/mirrored image to find the last zero on the left and first zero on the right.\n",
    "    \n",
    "    - or we can do rectification with a hard sigmoid (and something else to adjust for the small differences in >0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsm(t, dim=-1, tau=1, eps=1e-10):\n",
    "    return torch.nn.functional.gumbel_softmax(\n",
    "                                    t, \n",
    "                                    tau=tau,\n",
    "                                    eps=eps,\n",
    "                                    hard=True,\n",
    "                                    dim=dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demonstrate softmax across dimension {0, 1}\n",
    "\n",
    "Dim0 - across columns\n",
    "\n",
    "Dim1 - across rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., 10.,  3.],\n",
       "        [-2.,  6.,  8.],\n",
       "        [-4.,  3.,  2.]], requires_grad=True)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = torch.tensor([[0.,10.,3.], [-2.,6.,8.], [-4.,3.,2.]], \n",
    "                  dtype=torch.float,\n",
    "                  requires_grad=True)\n",
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 0.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm(a0, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm(a0, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above calc on `dim=1` does not always come out the smae way. Sometimes it is \"wrong(?)\" for the third row marking 2 as greater than 3?\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Arbitrary / \"Non-deterministic\" results for all zeros\n",
    "Below we see that column 1,2,1 are chosen but these are arbitrary selection. It would be better if each time the function would chose the first or the last zero-value.\n",
    "\n",
    "We also show that the result changes when the same calc is performed within a for-loop multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = torch.tensor([[0.,0.,0.], [0.,0.,0.], [0.,0.,0.]], \n",
    "                  dtype=torch.float,\n",
    "                  requires_grad=True)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff results on trial 0!\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.]], grad_fn=<AddBackward0>)\n",
      "vs.\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out1 = gsm(a1)\n",
    "for trial in range(10):\n",
    "    out2 = gsm(a1)\n",
    "    if (out1 != out2).any():\n",
    "        print(f'diff results on trial {trial}!\\n{out1}\\nvs.\\n{out2}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.gumbel_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine some rectification procedures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
